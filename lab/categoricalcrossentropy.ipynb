{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Categorical crossentropy is a loss function that is used in machine learning to train classification models. It is a measure of the difference between the predicted probability distribution of the model and the actual probability distribution of the data. The lower the categorical crossentropy, the better the model is at predicting the correct class.\n\nThe formula for categorical crossentropy is:\n\n```\nloss = -sum(y_true * log(y_pred))\n```\n\nwhere:\n\n* `y_true` is the ground truth label, a one-hot vector\n* `y_pred` is the model's prediction, a probability vector\n\nCategorical crossentropy is a differentiable function, which means that it can be used to train a model using gradient descent. Gradient descent is an iterative optimization algorithm that updates the model's parameters in the direction of the steepest descent of the loss function.\n\nCategorical crossentropy is a powerful loss function that can be used to train a variety of classification models. It is a good choice for problems where the classes are mutually exclusive, such as image classification or natural language processing.\n\nHere are some examples of how categorical crossentropy can be used:\n\n* Training a model to classify images of cats and dogs\n* Training a model to classify text as spam or ham\n* Training a model to classify handwritten digits\n\nIf you are facing a classification problem, and you have a large amount of data, then categorical crossentropy is a good loss function to consider.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ny_true = [[0, 1, 0], [0, 0, 1]]\ny_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n\ncce = tf.keras.losses.CategoricalCrossentropy()\ncce(y_true, y_pred).numpy()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-01T05:25:42.928953Z","iopub.execute_input":"2023-06-01T05:25:42.929793Z","iopub.status.idle":"2023-06-01T05:25:42.940695Z","shell.execute_reply.started":"2023-06-01T05:25:42.929758Z","shell.execute_reply":"2023-06-01T05:25:42.939590Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"1.1769392"},"metadata":{}}]}]}